{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3970738d-91a1-4fa3-9fef-1261a0289c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mofapy2 \n",
    "# !pip install mofax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5311dcf3-be20-4cc7-93cf-bc703d7b103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from mofapy2.run.entry_point import entry_point\n",
    "import mofax as mfx\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a908d6bd-ee65-462c-b51a-c691524e5142",
   "metadata": {},
   "source": [
    "## Phase 4 — Evaluation\n",
    "\n",
    "1. MOFA+ metrics (already computed)\n",
    "2. Stability analysis: LOOCV (multi-seed) → evaluate variance explained, factor replication rate, weight stability across runs  \n",
    "3. Sample-size sensitivity → variance explained and factor clustering as a function of sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf2380d-d455-424b-9cef-a48069b70bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Helper tools ====================\n",
    "class MOFAValidator:\n",
    "    \"\"\"\n",
    "    Comprehensive validation: LOOCV multi-seed and sample size sensitivity\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        pro: pd.DataFrame,\n",
    "        lipid: pd.DataFrame,\n",
    "        meta: pd.DataFrame,\n",
    "        views_names: List[str] = None,\n",
    "    ):\n",
    "        # Transpose: features × samples → samples × features\n",
    "        self.pro = pro.T\n",
    "        self.lipid = lipid.T\n",
    "        self.meta = meta.T\n",
    "        \n",
    "        self.views_names = ['proteomics', 'lipidomics', 'metabolomics']\n",
    "        \n",
    "        # Extract metadata\n",
    "        self.sample_names = self.pro.index.tolist()\n",
    "        self.n_samples = len(self.sample_names)\n",
    "        \n",
    "        self.pro_features = [f\"prot_{str(f)}\" for f in self.pro.columns.tolist()]\n",
    "        self.lipid_features = [f\"lipid_{str(f)}\" for f in self.lipid.columns.tolist()]\n",
    "        self.meta_features = [f\"meta_{str(f)}\" for f in self.meta.columns.tolist()]\n",
    "        \n",
    "        print(f\"Initialized validator:\")\n",
    "        print(f\"  Samples: {self.n_samples}\")\n",
    "        print(f\"  Proteomics features: {len(self.pro_features)}\")\n",
    "        print(f\"  Lipidomics features: {len(self.lipid_features)}\")\n",
    "        print(f\"  Metabolomics features: {len(self.meta_features)}\")\n",
    "\n",
    "    def loocv_multiseed(\n",
    "        self,\n",
    "        n_runs: int = 10,\n",
    "        base_seed: int = 2026,\n",
    "        factors: int = 10,\n",
    "        iterations: int = 1000,\n",
    "        save_dir: Optional[str] = None,\n",
    "        verbose: bool = False\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Leave-One-Out Cross-Validation with multiple seeds\n",
    "        \"\"\"\n",
    "        models = []\n",
    "        variance_results = {view: [] for view in self.views_names}\n",
    "        all_factors = []\n",
    "        all_weights = {view: [] for view in self.views_names}\n",
    "        \n",
    "        if save_dir:\n",
    "            save_dir = Path(save_dir)\n",
    "            save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        features_names = [\n",
    "            self.pro_features,\n",
    "            self.lipid_features,\n",
    "            self.meta_features\n",
    "        ]\n",
    "        \n",
    "        for run_idx in range(n_runs):\n",
    "            seed = base_seed + run_idx\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"\\n{'='*60}\")\n",
    "                print(f\"LOOCV Run {run_idx + 1}/{n_runs} (seed={seed})\")\n",
    "                print(f\"{'='*60}\")\n",
    "            \n",
    "            data_nested = [\n",
    "                [self.pro.values],\n",
    "                [self.lipid.values],\n",
    "                [self.meta.values]\n",
    "            ]\n",
    "            \n",
    "            # Train model\n",
    "            ent = entry_point()\n",
    "            ent.set_data_options(scale_views=True, scale_groups=False)\n",
    "\n",
    "            ent.set_data_matrix(\n",
    "                data=data_nested,\n",
    "                views_names=self.views_names,\n",
    "                groups_names=['group1'],\n",
    "                samples_names=[self.sample_names],\n",
    "                features_names=features_names\n",
    "            )\n",
    "            \n",
    "            ent.set_model_options(\n",
    "                factors=factors,\n",
    "                spikeslab_weights=True,\n",
    "                ard_factors=True,\n",
    "                ard_weights=True\n",
    "            )\n",
    "            \n",
    "            ent.set_train_options(\n",
    "                iter=iterations, \n",
    "                convergence_mode='medium', \n",
    "                dropR2=0.001, \n",
    "                seed=seed, \n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            ent.build()\n",
    "            ent.run()\n",
    "            \n",
    "            # Save model\n",
    "            if save_dir:\n",
    "                save_path = save_dir / f\"loocv_run_{run_idx + 1:02d}.hdf5\"\n",
    "                ent.save(str(save_path))\n",
    "            \n",
    "            # Extract results\n",
    "            variance = ent.model.calculate_variance_explained()\n",
    "            \n",
    "            # Extract the array (first element of the list)\n",
    "            variance_array = variance[0]  # Shape: (n_views, n_factors)\n",
    "            \n",
    "            # Sum across factors to get total R² per view\n",
    "            for view_idx, view in enumerate(self.views_names):\n",
    "                r2_total = variance_array[view_idx, :].sum()  # Sum across all factors\n",
    "                variance_results[view].append(r2_total)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  {view}: {r2_total:.2%}\")\n",
    "            \n",
    "            # Extract factors and weights\n",
    "            factors_loocv = ent.model.nodes['Z'].getExpectation()\n",
    "            weights_loocv = ent.model.nodes['W'].getExpectation()\n",
    "            \n",
    "            all_factors.append(factors_loocv)\n",
    "            for v_idx, view in enumerate(self.views_names):\n",
    "                all_weights[view].append(weights_loocv[v_idx])\n",
    "                        \n",
    "            models.append(ent)\n",
    "        \n",
    "        \n",
    "        # Calculate factor replication rate\n",
    "        replication_rate = self._calculate_factor_replication(all_factors)\n",
    "        \n",
    "        # Calculate weight stability\n",
    "        weight_stability = self._calculate_weight_stability(all_weights)\n",
    "\n",
    "        # Calculate stability\n",
    "        loocv_results = {\n",
    "            'models': models,\n",
    "            'variance_explained': variance_results,\n",
    "            'variance_summary': {},\n",
    "            'factors': all_factors,\n",
    "            'weights': all_weights,\n",
    "            'replication_rate': replication_rate,\n",
    "            'weight_stability': weight_stability\n",
    "        }\n",
    "        \n",
    "        for view in self.views_names:\n",
    "            loocv_results['variance_summary'][view] = {\n",
    "                'mean': np.mean(variance_results[view]),\n",
    "                'std': np.std(variance_results[view]),\n",
    "                'cv': np.std(variance_results[view]) / np.mean(variance_results[view]) * 100\n",
    "            }\n",
    "        \n",
    "        return loocv_results\n",
    "\n",
    "    def _calculate_factor_replication(self, all_factors: List[np.ndarray], threshold: float = 0.7) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate % of factors replicated across LOOCV Multi-seed samples\n",
    "        \"\"\"\n",
    "        ref_factors = all_factors[0]\n",
    "        n_factors = ref_factors.shape[1]\n",
    "        replication_counts = np.zeros(n_factors)\n",
    "        \n",
    "        for factors in all_factors[1:]:\n",
    "            corr_matrix = np.corrcoef(ref_factors.T, factors.T)[:n_factors, n_factors:]\n",
    "            max_corr = np.max(np.abs(corr_matrix), axis=1)\n",
    "            replication_counts += (max_corr > threshold).astype(int)\n",
    "        \n",
    "        replication_rate = replication_counts / (len(all_factors) - 1) * 100\n",
    "        return replication_rate\n",
    "    \n",
    "    def _calculate_weight_stability(self, all_weights: Dict[str, List[np.ndarray]]) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Calculate weight correlation across LOOCV Multi-seed samples\"\"\"\n",
    "        stability = {}\n",
    "        \n",
    "        for view, weights_list in all_weights.items():\n",
    "            ref_weights = weights_list[0]\n",
    "            n_factors = ref_weights.shape[1]\n",
    "            stabilities = []\n",
    "            \n",
    "            for weights in weights_list[1:]:\n",
    "                corr_matrix = np.corrcoef(ref_weights.T, weights.T)[:n_factors, n_factors:]\n",
    "                max_corr = np.max(np.abs(corr_matrix), axis=1)\n",
    "                stabilities.append(max_corr)\n",
    "            \n",
    "            stability[view] = np.mean(stabilities, axis=0)\n",
    "        \n",
    "        return stability\n",
    "    \n",
    "    def sample_size_sensitivity_simulated(\n",
    "        self,\n",
    "        target_sizes: List[int] = [20, 30, 40, 50],\n",
    "        n_replicates: int = 10,\n",
    "        base_seed: int = 2026,\n",
    "        factors: int = 10,\n",
    "        iterations: int = 1000,\n",
    "        verbose: bool = False\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Test MOFA+ with simulated larger datasets (this is feasible because the distribution has already been normalized and transformed)\n",
    "        \n",
    "        Generates synthetic samples by:\n",
    "        1. Fitting distributions to the real data \n",
    "        2. Sampling from those distributions\n",
    "        3. Testing MOFA+ stability with increasing n\n",
    "        \n",
    "        \"\"\"\n",
    "        ss_results = {\n",
    "            'sample_sizes': target_sizes,\n",
    "            'variance_explained': {view: {n: [] for n in target_sizes} for view in self.views_names}\n",
    "        }\n",
    "        \n",
    "        # Estimate data distributions from real data\n",
    "        pro_mean = self.pro.mean(axis=0)\n",
    "        pro_std = self.pro.std(axis=0)\n",
    "        \n",
    "        lipid_mean = self.lipid.mean(axis=0)\n",
    "        lipid_std = self.lipid.std(axis=0)\n",
    "        \n",
    "        meta_mean = self.meta.mean(axis=0)\n",
    "        meta_std = self.meta.std(axis=0)\n",
    "        \n",
    "        features_names = [\n",
    "            self.pro_features,\n",
    "            self.lipid_features,\n",
    "            self.meta_features\n",
    "        ]\n",
    "        \n",
    "        for n_size in target_sizes:\n",
    "            if verbose:\n",
    "                print(f\"\\nSimulating datasets with n={n_size}\")\n",
    "            \n",
    "            for rep in range(n_replicates):                \n",
    "                np.random.seed(base_seed + n_size * 100 + rep)\n",
    "\n",
    "                # Generate synthetic data from estimated distributions\n",
    "                synth_pro = np.random.normal(pro_mean, pro_std, size=(n_size, len(pro_mean)))\n",
    "                synth_lipid = np.random.normal(lipid_mean, lipid_std, size=(n_size, len(lipid_mean)))\n",
    "                synth_meta = np.random.normal(meta_mean, meta_std, size=(n_size, len(meta_mean)))\n",
    "\n",
    "                # Create unique sample names\n",
    "                synth_sample_names = [f\"synth_{n_size}_{rep}_{i}\" for i in range(n_size)]\n",
    "\n",
    "                # Train MOFA+ on synthetic data\n",
    "                data_nested = [\n",
    "                    [synth_pro],\n",
    "                    [synth_lipid],\n",
    "                    [synth_meta]\n",
    "                ]\n",
    "                \n",
    "                ent = entry_point()\n",
    "                ent.set_data_options(scale_views=True, scale_groups=False)\n",
    "\n",
    "                ent.set_data_matrix(\n",
    "                    data=data_nested,\n",
    "                    views_names=self.views_names,\n",
    "                    groups_names=['group1'],\n",
    "                    samples_names=[synth_sample_names],\n",
    "                    features_names=features_names\n",
    "                )\n",
    "                                \n",
    "                ent.set_model_options(\n",
    "                    factors=factors,\n",
    "                    spikeslab_weights=True,\n",
    "                    ard_factors=True,\n",
    "                    ard_weights=True\n",
    "                )\n",
    "                                \n",
    "                ent.set_train_options(\n",
    "                    iter=iterations,\n",
    "                    convergence_mode='fast',\n",
    "                    dropR2=0.001,\n",
    "                    seed=base_seed+rep,\n",
    "                    verbose=False\n",
    "                )\n",
    "                \n",
    "                try:\n",
    "                    ent.build()\n",
    "                    ent.run()\n",
    "                    \n",
    "                    variance = ent.model.calculate_variance_explained()\n",
    "                    variance_array = variance[0]\n",
    "                    \n",
    "                    for view_idx, view in enumerate(self.views_names):\n",
    "                        r2_total = variance_array[view_idx, :].sum()\n",
    "                        ss_results['variance_explained'][view][n_size].append(r2_total)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    if verbose:\n",
    "                        print(f\"  Error: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # Summaries\n",
    "        ss_results['summary'] = {}\n",
    "        for view in self.views_names:\n",
    "            ss_results['summary'][view] = {\n",
    "                n: {\n",
    "                    'mean': np.mean(vals) if vals else np.nan,\n",
    "                    'std': np.std(vals) if vals else np.nan\n",
    "                }\n",
    "                for n, vals in ss_results['variance_explained'][view].items()\n",
    "            }\n",
    "        \n",
    "        return ss_results\n",
    "\n",
    "class MOFAPlotter:\n",
    "    \"\"\"\n",
    "    Comprehensive plotting utilities for validation results\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def plot_loocv_var_stability(loocv_results: Dict, save_path: Optional[str] = None):\n",
    "        \"\"\"Plot variance explained stability across LOOCV runs\"\"\"\n",
    "        views = list(loocv_results['variance_explained'].keys())\n",
    "        n_runs = len(next(iter(loocv_results['variance_explained'].values())))\n",
    "    \n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "        colors = {\n",
    "            'proteomics': '#FFD700',\n",
    "            'lipidomics': '#440154',\n",
    "            'metabolomics': '#21918c'\n",
    "        }\n",
    "    \n",
    "        x = np.arange(1, n_runs + 1)\n",
    "    \n",
    "        for view in views:\n",
    "            y = loocv_results['variance_explained'][view]\n",
    "            ax.plot(\n",
    "                x,\n",
    "                y,\n",
    "                marker='o',\n",
    "                linewidth=2,\n",
    "                label=view,\n",
    "                color=colors.get(view, None)\n",
    "            )\n",
    "    \n",
    "            # Mean ± std band\n",
    "            mean = np.mean(y)\n",
    "            std = np.std(y)\n",
    "            ax.axhline(mean, linestyle='--', alpha=0.6, color=colors.get(view, None))\n",
    "            ax.fill_between(\n",
    "                x,\n",
    "                mean - std,\n",
    "                mean + std,\n",
    "                alpha=0.15,\n",
    "                color=colors.get(view, None)\n",
    "            )\n",
    "    \n",
    "        ax.set_xlabel('LOOCV Run', fontsize=12)\n",
    "        ax.set_ylabel('Variance Explained (R²)', fontsize=12)\n",
    "        ax.set_title('LOOCV Stability of Variance Explained per Omics View',\n",
    "                     fontsize=14, fontweight='bold')\n",
    "    \n",
    "        ax.legend(title='View')\n",
    "        ax.grid(alpha=0.3)\n",
    "    \n",
    "        plt.tight_layout()\n",
    "    \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_loocv_factorrep(loocv_factorep_results: Dict, save_path: Optional[str] = None):\n",
    "        \"\"\"Plot LOOCV Multi-seed factor replication rates\"\"\"\n",
    "        replication_rate = loocv_factorep_results['replication_rate']\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        \n",
    "        # Factor replication rate\n",
    "        n_factors = len(replication_rate)\n",
    "        axes[0].bar(range(1, n_factors + 1), replication_rate, alpha=0.8, edgecolor='black')\n",
    "        axes[0].axhline(70, color='red', linestyle='--', label='70% threshold')\n",
    "        axes[0].set_xlabel('Factor', fontsize=12)\n",
    "        axes[0].set_ylabel('Replication Rate (%)', fontsize=12)\n",
    "        axes[0].set_title('LOOCV Multi-seed Factor Replication', fontsize=13, fontweight='bold')\n",
    "        axes[0].set_xticks(range(1, n_factors + 1))\n",
    "        axes[0].set_xticklabels([f'F{i}' for i in range(1, n_factors + 1)])\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(alpha=0.3, axis='y')\n",
    "        \n",
    "        # Weight stability per view\n",
    "        weight_stability = loocv_factorep_results['weight_stability']\n",
    "        views = list(weight_stability.keys())\n",
    "        \n",
    "        x = np.arange(n_factors)\n",
    "        width = 0.25\n",
    "        colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "        \n",
    "        for idx, view in enumerate(views):\n",
    "            offset = (idx - 1) * width\n",
    "            axes[1].bar(x + offset, weight_stability[view], width,\n",
    "                       label=view, alpha=0.8, color=colors[idx])\n",
    "        \n",
    "        axes[1].set_xlabel('Factor', fontsize=12)\n",
    "        axes[1].set_ylabel('Weight Stability (correlation)', fontsize=12)\n",
    "        axes[1].set_title('Weight Stability per View', fontsize=13, fontweight='bold')\n",
    "        axes[1].set_xticks(x)\n",
    "        axes[1].set_xticklabels([f'F{i+1}' for i in range(n_factors)])\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_sample_size_sensitivity(sensitivity_results: Dict, save_path: Optional[str] = None):\n",
    "        \"\"\"Plot sample size sensitivity analysis\"\"\"\n",
    "        sample_sizes = sensitivity_results['sample_sizes']\n",
    "        views = list(sensitivity_results['summary'].keys())\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "        \n",
    "        # Variance explained vs sample size\n",
    "        colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "        for idx, view in enumerate(views):\n",
    "            means = [sensitivity_results['summary'][view][n]['mean'] for n in sample_sizes]\n",
    "            stds = [sensitivity_results['summary'][view][n]['std'] for n in sample_sizes]\n",
    "            \n",
    "            ax.plot(sample_sizes, means, marker='o', linewidth=2,\n",
    "                    label=view, color=colors[idx])\n",
    "            ax.fill_between(sample_sizes,\n",
    "                            np.array(means) - np.array(stds),\n",
    "                            np.array(means) + np.array(stds),\n",
    "                            alpha=0.2, color=colors[idx])\n",
    "        \n",
    "        ax.set_xlabel('Sample Size', fontsize=12)\n",
    "        ax.set_ylabel('Variance Explained (fraction)', fontsize=12)\n",
    "        ax.set_title('Variance Explained vs Sample Size', fontsize=14, fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f936821-c570-43c3-ac34-5bdebc922322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep the data\n",
    "\n",
    "# Load datasets\n",
    "proteins = pd.read_csv('data/proteins.csv')\n",
    "lipids = pd.read_csv('data/lipids.csv')\n",
    "metabolites = pd.read_csv('data/metabolites.csv')\n",
    "\n",
    "# Split labels and keep it separately\n",
    "pro_labels = proteins[proteins['sample'] == 'label'].iloc[0,1:].values\n",
    "lipid_labels = lipids[lipids['sample'] == 'label'].iloc[0,1:].values\n",
    "meta_labels = metabolites[metabolites['sample'] == 'label'].iloc[0,1:].values\n",
    "\n",
    "# Now remove the label row\n",
    "pro_nolabel = proteins[proteins['sample'] != 'label'].reset_index(drop=True)\n",
    "lipid_nolabel = lipids[lipids['sample'] != 'label'].reset_index(drop=True)\n",
    "meta_nolabel = metabolites[metabolites['sample'] != 'label'].reset_index(drop=True)\n",
    "\n",
    "# Set id_cols as index\n",
    "pro_nolabel = pro_nolabel.set_index('sample')\n",
    "lipid_nolabel = lipid_nolabel.set_index('sample')\n",
    "meta_nolabel = meta_nolabel.set_index('sample')\n",
    "\n",
    "# Filter proteins\n",
    "pro_nolabel = pro_nolabel.apply(pd.to_numeric, errors='coerce') \n",
    "pro_var = pro_nolabel.var(axis=1)\n",
    "top_proteins = (pro_var.nlargest(min(2000, len(pro_var))).index)\n",
    "pro_nolabel_filtered = pro_nolabel.loc[top_proteins]\n",
    "\n",
    "# Force all values to be numeric in case they are't\n",
    "lipid_nolabel = lipid_nolabel.apply(pd.to_numeric, errors='coerce') \n",
    "meta_nolabel = meta_nolabel.apply(pd.to_numeric, errors='coerce') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb76bc70-7224-44a1-a027-af56797453c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stability Analysis: LOOCV Multi-seed \n",
    "\n",
    "# Initialize validator\n",
    "validator = MOFAValidator(pro_nolabel_filtered, lipid_nolabel, meta_nolabel)\n",
    "\n",
    "# LOOCV Multi-seed\n",
    "print(\"\\n--- LOOCV Multi-Seed Analysis ---\")\n",
    "loocv_results = validator.loocv_multiseed(\n",
    "    n_runs=10,\n",
    "    base_seed=2026,\n",
    "    factors=10,\n",
    "    iterations=1000,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aafdd8-f8c5-4278-a9cf-bb6618382c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots LOOCV results\n",
    "output_dir = Path('plots/evaluation')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MOFAPlotter.plot_loocv_var_stability(loocv_results, save_path=str(output_dir / 'loocv_var_stability.png'))\n",
    "MOFAPlotter.plot_loocv_factorrep(loocv_results, save_path=str(output_dir / 'loocv_factorrep_and_wstability.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600a3d97-1a6d-4ecb-8faf-f908313c7a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample size sensitivity\n",
    "sensitivity_results = validator.sample_size_sensitivity_simulated(\n",
    "        target_sizes=[20, 30, 40, 50],\n",
    "        n_replicates=10,\n",
    "        base_seed=2026,\n",
    "        factors=10,\n",
    "        iterations=1000,\n",
    "        verbose=True)\n",
    "    \n",
    "MOFAPlotter.plot_sample_size_sensitivity(sensitivity_results, save_path=str(output_dir / 'sample_size_sensitivity.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9cb8f0-ba3e-4e9b-99d8-79ea456ef7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
